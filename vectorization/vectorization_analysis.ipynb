{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-05T17:47:44.300128Z",
     "start_time": "2025-06-05T17:47:43.509527Z"
    }
   },
   "source": [
    "from vectorize import apply_tfidf, apply_doc2vec, apply_sbert\n",
    "import pandas as pd\n",
    "import sys\n",
    "print(sys.executable)\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk import word_tokenize"
   ],
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "DLL load failed while importing _multiarray_umath: Das angegebene Modul wurde nicht gefunden.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[31mImportError\u001B[39m: DLL load failed while importing _multiarray_umath: Das angegebene Modul wurde nicht gefunden."
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "numpy._core.multiarray failed to import",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mImportError\u001B[39m                               Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[1]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mvectorize\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m apply_tfidf, apply_doc2vec, apply_sbert\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpandas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mpd\u001B[39;00m\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msys\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\PycharmProjects\\ML-XAI\\vectorization\\vectorize.py:1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01msklearn\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mfeature_extraction\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtext\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m TfidfVectorizer\n\u001B[32m      2\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mgensim\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mmodels\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mdoc2vec\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Doc2Vec, TaggedDocument\n\u001B[32m      3\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnltk\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01mtokenize\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m word_tokenize\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\sklearn\\__init__.py:73\u001B[39m\n\u001B[32m     62\u001B[39m \u001B[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001B[39;00m\n\u001B[32m     63\u001B[39m \u001B[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001B[39;00m\n\u001B[32m     64\u001B[39m \u001B[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m     67\u001B[39m \u001B[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001B[39;00m\n\u001B[32m     68\u001B[39m \u001B[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001B[39;00m\n\u001B[32m     69\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (  \u001B[38;5;66;03m# noqa: F401 E402\u001B[39;00m\n\u001B[32m     70\u001B[39m     __check_build,\n\u001B[32m     71\u001B[39m     _distributor_init,\n\u001B[32m     72\u001B[39m )\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mbase\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m clone  \u001B[38;5;66;03m# noqa: E402\u001B[39;00m\n\u001B[32m     74\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_show_versions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m show_versions  \u001B[38;5;66;03m# noqa: E402\u001B[39;00m\n\u001B[32m     76\u001B[39m _submodules = [\n\u001B[32m     77\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcalibration\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m     78\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcluster\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m   (...)\u001B[39m\u001B[32m    114\u001B[39m     \u001B[33m\"\u001B[39m\u001B[33mcompose\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    115\u001B[39m ]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\sklearn\\base.py:19\u001B[39m\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[32m     18\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mexceptions\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m InconsistentVersionWarning\n\u001B[32m---> \u001B[39m\u001B[32m19\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_estimator_html_repr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _HTMLDocumentationLinkMixin, estimator_html_repr\n\u001B[32m     20\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_metadata_requests\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _MetadataRequester, _routing_enabled\n\u001B[32m     21\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mutils\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m validate_parameter_constraints\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:9\u001B[39m\n\u001B[32m      7\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m metadata_routing\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_bunch\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Bunch\n\u001B[32m----> \u001B[39m\u001B[32m9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_chunking\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m gen_batches, gen_even_slices\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_estimator_html_repr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m estimator_html_repr\n\u001B[32m     12\u001B[39m \u001B[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001B[39;00m\n\u001B[32m     13\u001B[39m \u001B[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001B[39;00m\n\u001B[32m     14\u001B[39m \u001B[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001B[39;00m\n\u001B[32m     15\u001B[39m \u001B[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[38;5;66;03m# `_` in its name.\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001B[39m\n\u001B[32m      8\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m get_config\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_param_validation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Interval, validate_params\n\u001B[32m     14\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mchunk_generator\u001B[39m(gen, chunksize):\n\u001B[32m     15\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001B[39;00m\n\u001B[32m     16\u001B[39m \u001B[33;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:14\u001B[39m\n\u001B[32m     11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumbers\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m Integral, Real\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnumpy\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnp\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mscipy\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01msparse\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m csr_matrix, issparse\n\u001B[32m     16\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_config\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m config_context, get_config\n\u001B[32m     17\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01mvalidation\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _is_arraylike_not_scalar\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\scipy\\sparse\\__init__.py:295\u001B[39m\n\u001B[32m    292\u001B[39m \u001B[38;5;28;01mimport\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mwarnings\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mas\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m_warnings\u001B[39;00m\n\u001B[32m    294\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m--> \u001B[39m\u001B[32m295\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_csr\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m    296\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_csc\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n\u001B[32m    297\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_lil\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m *\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\Lib\\site-packages\\scipy\\sparse\\_csr.py:11\u001B[39m\n\u001B[32m      9\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_matrix\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m spmatrix\n\u001B[32m     10\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_base\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _spbase, sparray\n\u001B[32m---> \u001B[39m\u001B[32m11\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_sparsetools\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m (csr_tocsc, csr_tobsr, csr_count_blocks,\n\u001B[32m     12\u001B[39m                            get_csr_submatrix)\n\u001B[32m     13\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_sputils\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m upcast\n\u001B[32m     15\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01m.\u001B[39;00m\u001B[34;01m_compressed\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m _cs_matrix\n",
      "\u001B[31mImportError\u001B[39m: numpy._core.multiarray failed to import"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T17:46:45.574578400Z",
     "start_time": "2025-06-05T17:41:18.009819Z"
    }
   },
   "cell_type": "code",
   "source": "df = pd.read_pickle(\"../data/20newsgroup_preprocessed.pkl\")",
   "id": "5db6096f409a4edc",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy._core.numeric'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\pandas\\io\\pickle.py:202\u001B[39m, in \u001B[36mread_pickle\u001B[39m\u001B[34m(filepath_or_buffer, compression, storage_options)\u001B[39m\n\u001B[32m    201\u001B[39m         warnings.simplefilter(\u001B[33m\"\u001B[39m\u001B[33mignore\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;167;01mWarning\u001B[39;00m)\n\u001B[32m--> \u001B[39m\u001B[32m202\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m pickle.load(handles.handle)\n\u001B[32m    203\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m excs_to_catch:\n\u001B[32m    204\u001B[39m     \u001B[38;5;66;03m# e.g.\u001B[39;00m\n\u001B[32m    205\u001B[39m     \u001B[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001B[39;00m\n\u001B[32m    206\u001B[39m     \u001B[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'numpy._core.numeric'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m df = pd.read_pickle(\u001B[33m\"\u001B[39m\u001B[33m../data/20newsgroup_preprocessed.pkl\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\pandas\\io\\pickle.py:207\u001B[39m, in \u001B[36mread_pickle\u001B[39m\u001B[34m(filepath_or_buffer, compression, storage_options)\u001B[39m\n\u001B[32m    202\u001B[39m             \u001B[38;5;28;01mreturn\u001B[39;00m pickle.load(handles.handle)\n\u001B[32m    203\u001B[39m     \u001B[38;5;28;01mexcept\u001B[39;00m excs_to_catch:\n\u001B[32m    204\u001B[39m         \u001B[38;5;66;03m# e.g.\u001B[39;00m\n\u001B[32m    205\u001B[39m         \u001B[38;5;66;03m#  \"No module named 'pandas.core.sparse.series'\"\u001B[39;00m\n\u001B[32m    206\u001B[39m         \u001B[38;5;66;03m#  \"Can't get attribute '__nat_unpickle' on <module 'pandas._libs.tslib\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m207\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m pc.load(handles.handle, encoding=\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[32m    208\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mUnicodeDecodeError\u001B[39;00m:\n\u001B[32m    209\u001B[39m     \u001B[38;5;66;03m# e.g. can occur for files written in py27; see GH#28645 and GH#31988\u001B[39;00m\n\u001B[32m    210\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m pc.load(handles.handle, encoding=\u001B[33m\"\u001B[39m\u001B[33mlatin-1\u001B[39m\u001B[33m\"\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\pandas\\compat\\pickle_compat.py:231\u001B[39m, in \u001B[36mload\u001B[39m\u001B[34m(fh, encoding, is_verbose)\u001B[39m\n\u001B[32m    228\u001B[39m     \u001B[38;5;66;03m# \"Unpickler\" has no attribute \"is_verbose\"  [attr-defined]\u001B[39;00m\n\u001B[32m    229\u001B[39m     up.is_verbose = is_verbose  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m231\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m up.load()\n\u001B[32m    232\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m (\u001B[38;5;167;01mValueError\u001B[39;00m, \u001B[38;5;167;01mTypeError\u001B[39;00m):\n\u001B[32m    233\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\pickle.py:1256\u001B[39m, in \u001B[36m_Unpickler.load\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1254\u001B[39m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mEOFError\u001B[39;00m\n\u001B[32m   1255\u001B[39m         \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, bytes_types)\n\u001B[32m-> \u001B[39m\u001B[32m1256\u001B[39m         dispatch[key[\u001B[32m0\u001B[39m]](\u001B[38;5;28mself\u001B[39m)\n\u001B[32m   1257\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m _Stop \u001B[38;5;28;01mas\u001B[39;00m stopinst:\n\u001B[32m   1258\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m stopinst.value\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\pickle.py:1581\u001B[39m, in \u001B[36m_Unpickler.load_stack_global\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1579\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(name) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mstr\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mtype\u001B[39m(module) \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mstr\u001B[39m:\n\u001B[32m   1580\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m UnpicklingError(\u001B[33m\"\u001B[39m\u001B[33mSTACK_GLOBAL requires str\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m-> \u001B[39m\u001B[32m1581\u001B[39m \u001B[38;5;28mself\u001B[39m.append(\u001B[38;5;28mself\u001B[39m.find_class(module, name))\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\pandas\\compat\\pickle_compat.py:162\u001B[39m, in \u001B[36mUnpickler.find_class\u001B[39m\u001B[34m(self, module, name)\u001B[39m\n\u001B[32m    160\u001B[39m key = (module, name)\n\u001B[32m    161\u001B[39m module, name = _class_locations_map.get(key, key)\n\u001B[32m--> \u001B[39m\u001B[32m162\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m().find_class(module, name)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\pickle.py:1622\u001B[39m, in \u001B[36m_Unpickler.find_class\u001B[39m\u001B[34m(self, module, name)\u001B[39m\n\u001B[32m   1620\u001B[39m     \u001B[38;5;28;01melif\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m _compat_pickle.IMPORT_MAPPING:\n\u001B[32m   1621\u001B[39m         module = _compat_pickle.IMPORT_MAPPING[module]\n\u001B[32m-> \u001B[39m\u001B[32m1622\u001B[39m \u001B[38;5;28m__import__\u001B[39m(module, level=\u001B[32m0\u001B[39m)\n\u001B[32m   1623\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.proto >= \u001B[32m4\u001B[39m:\n\u001B[32m   1624\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m _getattribute(sys.modules[module], name)[\u001B[32m0\u001B[39m]\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'numpy._core.numeric'"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-05T17:46:45.605919300Z",
     "start_time": "2025-06-05T16:26:01.726891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from nltk import word_tokenize\n",
    "\n",
    "\n",
    "def prepare_tagged_data(docs):\n",
    "    \"\"\"Tokenizes and tags documents for Doc2Vec training.\"\"\"\n",
    "    return [TaggedDocument(words=word_tokenize(doc.lower()), tags=[str(i)]) for i, doc in enumerate(docs)]\n",
    "\n",
    "def apply_doc2vec(docs, vector_size=100, epochs=20, window=5, min_count=2):\n",
    "    tagged_data = prepare_tagged_data(docs)\n",
    "    model = Doc2Vec(vector_size=vector_size, window=window, min_count=min_count, workers=4)\n",
    "    model.build_vocab(tagged_data)\n",
    "    model.train(tagged_data, total_examples=model.corpus_count, epochs=epochs)\n",
    "\n",
    "    # Inference: convert each doc to a vector\n",
    "    vectors = [model.infer_vector(word_tokenize(doc.lower())) for doc in docs]\n",
    "    return vectors, model"
   ],
   "id": "5e8ae64fd6c5f932",
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nltk'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mModuleNotFoundError\u001B[39m                       Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[6]\u001B[39m\u001B[32m, line 1\u001B[39m\n\u001B[32m----> \u001B[39m\u001B[32m1\u001B[39m \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01mnltk\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;28;01mimport\u001B[39;00m word_tokenize\n\u001B[32m      4\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mprepare_tagged_data\u001B[39m(docs):\n\u001B[32m      5\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Tokenizes and tags documents for Doc2Vec training.\"\"\"\u001B[39;00m\n",
      "\u001B[31mModuleNotFoundError\u001B[39m: No module named 'nltk'"
     ]
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
