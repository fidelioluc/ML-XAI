{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-12T18:18:10.580702Z",
     "start_time": "2025-06-12T18:18:10.569084Z"
    }
   },
   "source": [
    "from utils import lime_explanation\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "from sklearn.pipeline import make_pipeline\n"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T18:22:27.640506Z",
     "start_time": "2025-06-12T18:22:26.026693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "data = fetch_20newsgroups(subset='all',remove=('headers', 'footers', 'quotes'))\n",
    "df = pd.DataFrame({\n",
    "    'text': data.data,\n",
    "    'target': data.target,\n",
    "    'target_name': [data.target_names[i] for i in data.target]\n",
    "})\n",
    "\n",
    "class_names = df[\"target_name\"].unique()\n",
    "\n",
    "text_instance = df[\"text\"].sample(n=1).values[0]\n",
    "\n",
    "classifier = joblib.load(\"../02_classification/text_classifier.pkl\")\n"
   ],
   "id": "de1419b0b3d38a27",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T18:22:32.095141Z",
     "start_time": "2025-06-12T18:22:29.949151Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df[\"text\"])"
   ],
   "id": "c3bb7f9acfcc5cc9",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T18:24:34.332363Z",
     "start_time": "2025-06-12T18:24:33.782285Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pipeline = make_pipeline(tfidf_vectorizer, classifier)\n",
    "\n",
    "# Now classifier can handle it\n",
    "\n",
    "def lime_explanations(model, class_names, text_instance):\n",
    "    explainer = LimeTextExplainer(class_names=class_names)\n",
    "    explanation = explainer.explain_instance(\n",
    "        text_instance,\n",
    "        model.predict_proba,     # must accept raw text\n",
    "        num_features=10\n",
    "    )\n",
    "    return explanation\n",
    "\n",
    "explanations = lime_explanations(pipeline, class_names, text_instance)\n",
    "explanations.show_in_notebook()"
   ],
   "id": "d42cd823efbb27c5",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 134410 features, but SVC is expecting 50 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mValueError\u001B[39m                                Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 14\u001B[39m\n\u001B[32m      7\u001B[39m     explanation = explainer.explain_instance(\n\u001B[32m      8\u001B[39m         text_instance,\n\u001B[32m      9\u001B[39m         model.predict_proba,     \u001B[38;5;66;03m# must accept raw text\u001B[39;00m\n\u001B[32m     10\u001B[39m         num_features=\u001B[32m10\u001B[39m\n\u001B[32m     11\u001B[39m     )\n\u001B[32m     12\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m explanation\n\u001B[32m---> \u001B[39m\u001B[32m14\u001B[39m explanations = lime_explanations(pipeline, class_names, text_instance)\n\u001B[32m     15\u001B[39m explanations.show_in_notebook()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[23]\u001B[39m\u001B[32m, line 7\u001B[39m, in \u001B[36mlime_explanations\u001B[39m\u001B[34m(model, class_names, text_instance)\u001B[39m\n\u001B[32m      5\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mlime_explanations\u001B[39m(model, class_names, text_instance):\n\u001B[32m      6\u001B[39m     explainer = LimeTextExplainer(class_names=class_names)\n\u001B[32m----> \u001B[39m\u001B[32m7\u001B[39m     explanation = explainer.explain_instance(\n\u001B[32m      8\u001B[39m         text_instance,\n\u001B[32m      9\u001B[39m         model.predict_proba,     \u001B[38;5;66;03m# must accept raw text\u001B[39;00m\n\u001B[32m     10\u001B[39m         num_features=\u001B[32m10\u001B[39m\n\u001B[32m     11\u001B[39m     )\n\u001B[32m     12\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m explanation\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\lime\\lime_text.py:413\u001B[39m, in \u001B[36mLimeTextExplainer.explain_instance\u001B[39m\u001B[34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001B[39m\n\u001B[32m    406\u001B[39m indexed_string = (IndexedCharacters(\n\u001B[32m    407\u001B[39m     text_instance, bow=\u001B[38;5;28mself\u001B[39m.bow, mask_string=\u001B[38;5;28mself\u001B[39m.mask_string)\n\u001B[32m    408\u001B[39m                   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.char_level \u001B[38;5;28;01melse\u001B[39;00m\n\u001B[32m    409\u001B[39m                   IndexedString(text_instance, bow=\u001B[38;5;28mself\u001B[39m.bow,\n\u001B[32m    410\u001B[39m                                 split_expression=\u001B[38;5;28mself\u001B[39m.split_expression,\n\u001B[32m    411\u001B[39m                                 mask_string=\u001B[38;5;28mself\u001B[39m.mask_string))\n\u001B[32m    412\u001B[39m domain_mapper = TextDomainMapper(indexed_string)\n\u001B[32m--> \u001B[39m\u001B[32m413\u001B[39m data, yss, distances = \u001B[38;5;28mself\u001B[39m.__data_labels_distances(\n\u001B[32m    414\u001B[39m     indexed_string, classifier_fn, num_samples,\n\u001B[32m    415\u001B[39m     distance_metric=distance_metric)\n\u001B[32m    416\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.class_names \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    417\u001B[39m     \u001B[38;5;28mself\u001B[39m.class_names = [\u001B[38;5;28mstr\u001B[39m(x) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(yss[\u001B[32m0\u001B[39m].shape[\u001B[32m0\u001B[39m])]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\lime\\lime_text.py:482\u001B[39m, in \u001B[36mLimeTextExplainer.__data_labels_distances\u001B[39m\u001B[34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001B[39m\n\u001B[32m    480\u001B[39m     data[i, inactive] = \u001B[32m0\u001B[39m\n\u001B[32m    481\u001B[39m     inverse_data.append(indexed_string.inverse_removing(inactive))\n\u001B[32m--> \u001B[39m\u001B[32m482\u001B[39m labels = classifier_fn(inverse_data)\n\u001B[32m    483\u001B[39m distances = distance_fn(sp.sparse.csr_matrix(data))\n\u001B[32m    484\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m data, labels, distances\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\sklearn\\pipeline.py:904\u001B[39m, in \u001B[36mPipeline.predict_proba\u001B[39m\u001B[34m(self, X, **params)\u001B[39m\n\u001B[32m    902\u001B[39m     \u001B[38;5;28;01mfor\u001B[39;00m _, name, transform \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m._iter(with_final=\u001B[38;5;28;01mFalse\u001B[39;00m):\n\u001B[32m    903\u001B[39m         Xt = transform.transform(Xt)\n\u001B[32m--> \u001B[39m\u001B[32m904\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m.steps[-\u001B[32m1\u001B[39m][\u001B[32m1\u001B[39m].predict_proba(Xt, **params)\n\u001B[32m    906\u001B[39m \u001B[38;5;66;03m# metadata routing enabled\u001B[39;00m\n\u001B[32m    907\u001B[39m routed_params = process_routing(\u001B[38;5;28mself\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mpredict_proba\u001B[39m\u001B[33m\"\u001B[39m, **params)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\sklearn\\svm\\_base.py:865\u001B[39m, in \u001B[36mBaseSVC.predict_proba\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    838\u001B[39m \u001B[38;5;129m@available_if\u001B[39m(_check_proba)\n\u001B[32m    839\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mpredict_proba\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[32m    840\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"Compute probabilities of possible outcomes for samples in X.\u001B[39;00m\n\u001B[32m    841\u001B[39m \n\u001B[32m    842\u001B[39m \u001B[33;03m    The model needs to have probability information computed at training\u001B[39;00m\n\u001B[32m   (...)\u001B[39m\u001B[32m    863\u001B[39m \u001B[33;03m    datasets.\u001B[39;00m\n\u001B[32m    864\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m865\u001B[39m     X = \u001B[38;5;28mself\u001B[39m._validate_for_predict(X)\n\u001B[32m    866\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.probA_.size == \u001B[32m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m.probB_.size == \u001B[32m0\u001B[39m:\n\u001B[32m    867\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(\n\u001B[32m    868\u001B[39m             \u001B[33m\"\u001B[39m\u001B[33mpredict_proba is not available when fitted with probability=False\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    869\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\sklearn\\svm\\_base.py:614\u001B[39m, in \u001B[36mBaseLibSVM._validate_for_predict\u001B[39m\u001B[34m(self, X)\u001B[39m\n\u001B[32m    611\u001B[39m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[32m    613\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(\u001B[38;5;28mself\u001B[39m.kernel):\n\u001B[32m--> \u001B[39m\u001B[32m614\u001B[39m     X = validate_data(\n\u001B[32m    615\u001B[39m         \u001B[38;5;28mself\u001B[39m,\n\u001B[32m    616\u001B[39m         X,\n\u001B[32m    617\u001B[39m         accept_sparse=\u001B[33m\"\u001B[39m\u001B[33mcsr\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    618\u001B[39m         dtype=np.float64,\n\u001B[32m    619\u001B[39m         order=\u001B[33m\"\u001B[39m\u001B[33mC\u001B[39m\u001B[33m\"\u001B[39m,\n\u001B[32m    620\u001B[39m         accept_large_sparse=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    621\u001B[39m         reset=\u001B[38;5;28;01mFalse\u001B[39;00m,\n\u001B[32m    622\u001B[39m     )\n\u001B[32m    624\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sparse \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m sp.issparse(X):\n\u001B[32m    625\u001B[39m     X = sp.csr_matrix(X)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\sklearn\\utils\\validation.py:2965\u001B[39m, in \u001B[36mvalidate_data\u001B[39m\u001B[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001B[39m\n\u001B[32m   2962\u001B[39m     out = X, y\n\u001B[32m   2964\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params.get(\u001B[33m\"\u001B[39m\u001B[33mensure_2d\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[32m-> \u001B[39m\u001B[32m2965\u001B[39m     _check_n_features(_estimator, X, reset=reset)\n\u001B[32m   2967\u001B[39m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\sklearn\\utils\\validation.py:2829\u001B[39m, in \u001B[36m_check_n_features\u001B[39m\u001B[34m(estimator, X, reset)\u001B[39m\n\u001B[32m   2826\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[32m   2828\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n_features != estimator.n_features_in_:\n\u001B[32m-> \u001B[39m\u001B[32m2829\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[32m   2830\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator.\u001B[34m__class__\u001B[39m.\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2831\u001B[39m         \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator.n_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m features as input.\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   2832\u001B[39m     )\n",
      "\u001B[31mValueError\u001B[39m: X has 134410 features, but SVC is expecting 50 features as input."
     ]
    }
   ],
   "execution_count": 23
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
