{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T08:31:42.754537Z",
     "start_time": "2025-06-11T08:31:31.976686Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jonas\\OneDrive\\Desktop\\Studium_OvGU\\Master\\SoSe25\\ML\\XAI\\ML-XAI\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from vectorize import apply_tfidf, apply_doc2vec, apply_sbert\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5db6096f409a4edc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T08:31:42.909355Z",
     "start_time": "2025-06-11T08:31:42.764831Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../00_data_cleaning/out/20newsgroup_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "878e2b1896a94feb",
   "metadata": {},
   "source": [
    "## TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e8ae64fd6c5f932",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T08:31:44.706515Z",
     "start_time": "2025-06-11T08:31:43.420252Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    aa  aaa  aamir  aan  aap  aarhus  aaron  aax   ab  ababa  ...  zurich  \\\n",
      "0  0.0  0.0    0.0  0.0  0.0     0.0    0.0  0.0  0.0    0.0  ...     0.0   \n",
      "1  0.0  0.0    0.0  0.0  0.0     0.0    0.0  0.0  0.0    0.0  ...     0.0   \n",
      "2  0.0  0.0    0.0  0.0  0.0     0.0    0.0  0.0  0.0    0.0  ...     0.0   \n",
      "3  0.0  0.0    0.0  0.0  0.0     0.0    0.0  0.0  0.0    0.0  ...     0.0   \n",
      "4  0.0  0.0    0.0  0.0  0.0     0.0    0.0  0.0  0.0    0.0  ...     0.0   \n",
      "\n",
      "    zv  zvfd  zvi  zvm   zw   zx   zy  zyxel   zz  \n",
      "0  0.0   0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  \n",
      "1  0.0   0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  \n",
      "2  0.0   0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  \n",
      "3  0.0   0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  \n",
      "4  0.0   0.0  0.0  0.0  0.0  0.0  0.0    0.0  0.0  \n",
      "\n",
      "[5 rows x 35000 columns]\n"
     ]
    }
   ],
   "source": [
    "df[\"text\"] = df[\"text\"].fillna(\"\")\n",
    "\n",
    "X_tfidf, tfidf_vectorizer = apply_tfidf(\n",
    "    df[\"text\"], 35000\n",
    ")  # TODO: adjust features_ctr as needed\n",
    "\n",
    "tfidf_df = pd.DataFrame(\n",
    "    X_tfidf.toarray(), columns=tfidf_vectorizer.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049886a95ef9bc7",
   "metadata": {},
   "source": [
    "## Save Artifacts (sparse matrix, model, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b701e28924540852",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T08:49:23.178435Z",
     "start_time": "2025-06-11T08:49:23.173395Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"out/tf_idf/X_tfidf.npz\", \"wb\") as f:\n",
    "    pickle.dump(X_tfidf, f)\n",
    "\n",
    "with open(\"out/tf_idf/tfidf_vectorizer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fd1b04dc3087ae",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3bca75506a4cdb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T08:33:32.177525Z",
     "start_time": "2025-06-11T08:31:44.756349Z"
    }
   },
   "outputs": [],
   "source": [
    "d2v_vectors, d2v_model = apply_doc2vec(df[\"text\"])\n",
    "\n",
    "vectors = np.array(d2v_vectors)\n",
    "\n",
    "np.save(\"out/doc2vec/d2v_vectors.npy\", vectors)\n",
    "d2v_model.save(\"out/doc2vec/d2v_model.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f6d87ec868c814",
   "metadata": {},
   "source": [
    "## SBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce5a6ab00401285",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T08:39:17.515017Z",
     "start_time": "2025-06-11T08:35:41.768306Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fidel\\miniconda3\\envs\\ML-XAI\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\fidel\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    }
   ],
   "source": [
    "sbert_vectors, sbert_model = apply_sbert(df[\"text\"])\n",
    "\n",
    "vectors = np.array(sbert_vectors)\n",
    "\n",
    "np.save(\"out/sbert/sbert_vectors.npy\", vectors)\n",
    "sbert_model.save(\"out/sbert/sbert_model.model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
